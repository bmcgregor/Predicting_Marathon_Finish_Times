{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Web Scraping - London Marathon Results 2014-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Project - BSTN Capstone__\n",
    "<br>__Beth McGregor__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code used for web scraping the results of the London Marathon from 2014-2019. The results for each year were stored in either html for table format. The results were retrieved, processed and saved into csv files by year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import html5lib\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the London Marathon results where results are stored in a table format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This will retrieve years prior to 2019 where the results are stored in a table format\n",
    "def get_london_results(year, event_code, gender):\n",
    "    \n",
    "    URL = 'https://results.virginmoneylondonmarathon.com/'+y+'/?page=1&event='+event_code+'&num_results=1000&pid=list&search%5Bsex%5D='+gender+'&search%5Bage_class%5D=%25'\n",
    "    response = requests.get(URL)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # find the maximum number of result pages\n",
    "    max_page = 1\n",
    "    \n",
    "    page_elements = html_soup.select('div.pages a')\n",
    "    if len(page_elements) > 0:\n",
    "        max_page = int(page_elements[-2].get_text())\n",
    "    else: \n",
    "        page_elements = html_soup.select('div.pages li.hidden-xs')\n",
    "        if len(page_elements) > 0:                                \n",
    "            max_page = int(page_elements[-1].get_text())\n",
    "    \n",
    "    results_df = pd.read_html(response.content)[0]\n",
    "    \n",
    "    results_df['gender'] = gender\n",
    "    results_df['year'] = year\n",
    "    \n",
    "    for p in range(2,max_page+1):\n",
    "        print(\"Page: \", p, \"/\", max_page)\n",
    "        #making a request\n",
    "        URL2= 'https://results.virginmoneylondonmarathon.com/'+y+'/?page='+str(p)+'&event='+event_code+'&num_results=1000&pid=list&search%5Bsex%5D='+gender+'&search%5Bage_class%5D=%25'\n",
    "        html_doc = requests.get(URL2).content\n",
    "        race_output_df = pd.read_html(html_doc)[0]\n",
    "        race_output_df['gender'] = gender\n",
    "        race_output_df['year'] = year       \n",
    "        results_df = pd.concat([results_df, race_output_df])\n",
    "        #pausing the script\n",
    "        sleep(randint(2,5))\n",
    "\n",
    "    return results_df     \n",
    "    \n",
    "\n",
    "\n",
    "year = [\"2014\",\"2015\", \"2016\", \"2017\", \"2018\"]\n",
    "                                \n",
    "#looping over years\n",
    "for y in year:\n",
    "    print(\"Year: \", y)\n",
    "    year_race_results_M = get_london_results(year = y, event_code = \"MAS\", gender = \"M\")\n",
    "    year_race_results_W = get_london_results(year = y, event_code = \"MAS\", gender = \"W\")\n",
    "    year_race_results_ME = get_london_results(year = y, event_code = \"ELIT\", gender = \"M\")\n",
    "    year_race_results_WE = get_london_results(year = y, event_code = \"ELIT\", gender = \"W\")\n",
    "    race_results_year_df = pd.concat([year_race_results_M, year_race_results_W, year_race_results_ME, year_race_results_WE])\n",
    "    \n",
    "    #columns to drop\n",
    "    drop_list = [\"Unnamed: 4\", \"Club\", \"Unnamed: 10\", \"Place category\", \"Unnamed: 9\", \"Place cat.\"]\n",
    "    race_results_filter = race_results_year_df.filter(drop_list)\n",
    "    race_results_year_df.drop(race_results_filter, inplace=True, axis=1)\n",
    "\n",
    "    race_results_year_df[\"Name\"] = race_results_year_df[\"Name\"].str.replace(\"Â» \", \"\")\n",
    "    race_results_year_df.to_csv(f'London_race_results_{y}.csv')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve the results for 2019 (and other years) where the results are not stored in a table format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2019\n",
      "Page:  1 / 25\n",
      "1001\n",
      "Page:  2 / 25\n",
      "1001\n",
      "Page:  3 / 25\n",
      "1001\n",
      "Page:  4 / 25\n",
      "1001\n",
      "Page:  5 / 25\n",
      "1001\n",
      "Page:  6 / 25\n",
      "1001\n",
      "Page:  7 / 25\n",
      "1001\n",
      "Page:  8 / 25\n",
      "1001\n",
      "Page:  9 / 25\n",
      "1001\n",
      "Page:  10 / 25\n",
      "1001\n",
      "Page:  11 / 25\n",
      "1001\n",
      "Page:  12 / 25\n",
      "1001\n",
      "Page:  13 / 25\n",
      "1001\n",
      "Page:  14 / 25\n",
      "1001\n",
      "Page:  15 / 25\n",
      "1001\n",
      "Page:  16 / 25\n",
      "1001\n",
      "Page:  17 / 25\n",
      "1001\n",
      "Page:  18 / 25\n",
      "1001\n",
      "Page:  19 / 25\n",
      "1001\n",
      "Page:  20 / 25\n",
      "1001\n",
      "Page:  21 / 25\n",
      "1001\n",
      "Page:  22 / 25\n",
      "1001\n",
      "Page:  23 / 25\n",
      "1001\n",
      "Page:  24 / 25\n",
      "1001\n",
      "Page:  25 / 25\n",
      "780\n",
      "Page:  1 / 18\n",
      "1001\n",
      "Page:  2 / 18\n",
      "1001\n",
      "Page:  3 / 18\n",
      "1001\n",
      "Page:  4 / 18\n",
      "1001\n",
      "Page:  5 / 18\n",
      "1001\n",
      "Page:  6 / 18\n",
      "1001\n",
      "Page:  7 / 18\n",
      "1001\n",
      "Page:  8 / 18\n",
      "1001\n",
      "Page:  9 / 18\n",
      "1001\n",
      "Page:  10 / 18\n",
      "1001\n",
      "Page:  11 / 18\n",
      "1001\n",
      "Page:  12 / 18\n",
      "1001\n",
      "Page:  13 / 18\n",
      "1001\n",
      "Page:  14 / 18\n",
      "1001\n",
      "Page:  15 / 18\n",
      "1001\n",
      "Page:  16 / 18\n",
      "1001\n",
      "Page:  17 / 18\n",
      "1001\n",
      "Page:  18 / 18\n",
      "783\n",
      "Page:  1 / 1\n",
      "37\n",
      "Page:  1 / 1\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# This will retrieve the results for 2019 (and other years) where the results are not stored in a table format\n",
    "def get_london_results(year, event_code, gender):\n",
    "    race_results = []\n",
    "    URL = 'https://results.virginmoneylondonmarathon.com/'+y+'/?page=1&event='+event_code+'&num_results=1000&pid=list&search%5Bsex%5D='+gender+'&search%5Bage_class%5D=%25'\n",
    "    content = requests.get(URL)\n",
    "    html_soup = BeautifulSoup(content.text, 'html.parser')\n",
    "\n",
    "    # find the maximum number of result pages\n",
    "    max_page = 1\n",
    "    \n",
    "    page_elements = html_soup.select('div.pages a')\n",
    "    if len(page_elements) > 0:\n",
    "        max_page = int(page_elements[-2].get_text())\n",
    "    else: \n",
    "        page_elements = html_soup.select('div.pages li.hidden-xs')\n",
    "        if len(page_elements) > 0:                                \n",
    "            max_page = int(page_elements[-1].get_text())\n",
    "    \n",
    "    for p in range(1,max_page+1):\n",
    "        print(\"Page: \", p, \"/\", max_page)\n",
    "        #making a request\n",
    "        URL2= 'https://results.virginmoneylondonmarathon.com/'+y+'/?page='+str(p)+'&event='+event_code+'&num_results=1000&pid=list&search%5Bsex%5D='+gender+'&search%5Bage_class%5D=%25'\n",
    "        content = requests.get(URL2)\n",
    "        html_soup = BeautifulSoup(content.text, 'html.parser')\n",
    "        elements = html_soup.select(\"li.list-group-item.row\")\n",
    "        \n",
    "        #pausing the script\n",
    "        sleep(randint(2,5))\n",
    "      \n",
    "\n",
    "        print(len(elements))\n",
    "        for row in elements[1:]: \n",
    "            runner = {}\n",
    "            runner['place_overall'] = row.select_one('.place-secondary').get_text()\n",
    "            runner['place_gender'] = row.select_one('.place-primary').get_text()\n",
    "            runner['full_name'] = row.select_one('.type-fullname').get_text()\n",
    "            runner['bib_number'] = row.select('.type-field')[1].contents[1]\n",
    "            runner['age_class'] = row.select_one('.type-age_class').contents[1]\n",
    "            runner['half_split'] = row.select('.type-time')[0].contents[1]\n",
    "            runner['finish_time'] = row.select('.type-time')[1].contents[1]\n",
    "            runner['gender'] = gender\n",
    "            runner['year'] = year\n",
    "            race_results.append(runner)  \n",
    "\n",
    "    return race_results\n",
    "\n",
    "\n",
    "year = [\"2019\"]\n",
    "\n",
    "\n",
    "#looping over years\n",
    "for y in year:\n",
    "    print(\"Year: \", y)\n",
    "    year_race_results = get_london_results(year = y, event_code = \"MAS\", gender = \"M\")\n",
    "    year_race_results = year_race_results + get_london_results(year = y, event_code = \"MAS\", gender = \"W\")\n",
    "    year_race_results = year_race_results + get_london_results(year = y, event_code = \"ELIT\", gender = \"M\")\n",
    "    year_race_results = year_race_results + get_london_results(year = y, event_code = \"ELIT\", gender = \"W\")\n",
    "    race_results_year_df = pd.DataFrame(year_race_results)\n",
    "    race_results_year_df.to_csv(f'London_race_results_{y}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
